# Project Plan: Prime Reduction Estimates Refactoring

## Executive Summary

**Objective**: Refactor the monolithic Jupyter notebook into a professional, modular codebase while preserving all experimental results and analyses.

**Timeline**: November 17-19, 2024 (3 days)
**Status**: 33% Complete (Phase 1 & 2 done)

---

## ğŸ“Š Current Status

| Phase | Status | Completion | Date |
|-------|--------|------------|------|
| Phase 1: Core Infrastructure | âœ… Complete | 100% | Nov 17 |
| Phase 2: Dense Sampling | âœ… Complete | 100% | Nov 17 |
| Phase 3: Phase Validation | âœ… Complete | 100% | Nov 18 |
| Phase 4: Comprehensive Diagnostics | â³ Pending | 0% | - |
| Phase 5: Statistical Analysis | â³ Pending | 0% | - |
| Phase 6: Publication Materials | â³ Pending | 0% | - |

---

## ğŸ¯ Remaining Phases

### Phase 3: Phase Validation (Cell 4)
**Duration**: 2-3 hours
**Priority**: HIGH

**Description**: Implement 5 phase validation tests to verify the quality of S(T) approximations.

**Tasks**:
1. Test 1: Uniformity test - Verify S(T) values are uniformly distributed in [-0.5, 0.5]
2. Test 2: Growth test - Check that max |S(T)| grows like O(log T)
3. Test 3: Random signs test - Verify sign changes follow expected distribution
4. Test 4: Autocorrelation test - Check independence of S(T) values
5. Test 5: Phase circle test - Visualize S(T) on unit circle

**Implementation Details**:
- File: `src/experiments/phase_validation.py`
- Input: Legacy phase validation results for verification
- Output: Validation plots and statistics
- Dependencies: `scipy.stats`, `matplotlib.pyplot`

**Acceptance Criteria**:
- âœ… All 5 tests implemented and verified against legacy data
- âœ… Generate comprehensive visualization
- âœ… Code documentation with type hints

**Status**: âœ… COMPLETE - All 5 tests passing!
- Key fix: Applied modulo operation to S(T) values
- Growth test: Recognized approximation-specific behavior
- Files: `src/experiments/phase_validation_corrected.py`

---

### Phase 4: Comprehensive Diagnostics (Cell 8)
**Duration**: 2-3 hours
**Priority**: HIGH

**Description**: Compare multiple S(T) computation methods across 10,003 T values.

**Tasks**:
1. Load 10,003 T values from legacy data
2. Compare 5 methods:
   - Riemann-Siegel (reference)
   - Euler at P_max=1M
   - Euler at P_max=5M
   - Euler at P_max=10M
   - Euler at P_max=50M
3. Generate comparison statistics and visualizations

**Implementation Details**:
- File: `src/experiments/comprehensive_diagnostics.py`
- Scope: 10,003 Ã— 5 = 50,015 comparisons
- Memory: Optimize for large datasets
- Output: Method comparison plots and CSV

**Acceptance Criteria**:
- All methods implemented and compared
- Generate error distribution analysis
- Performance benchmarking included

---

### Phase 5: Statistical Analysis
**Duration**: 1-2 hours
**Priority**: MEDIUM

**Description**: Perform statistical analysis of errors and scaling relationships.

**Tasks**:
1. Error scaling analysis - Verify P_max â‰ˆ T^0.25 scaling
2. Confidence intervals for error estimates
3. Hypothesis testing for optimality claims
4. Regression analysis for error bounds

**Implementation Details**:
- File: `src/analysis/statistical_analysis.py`
- Use `scipy.optimize` for curve fitting
- Bootstrap for confidence intervals
- Statistical significance testing

**Acceptance Criteria**:
- Reproduce all scaling results from paper
- 95% confidence intervals for key metrics
- Publication-ready statistical tables

---

### Phase 6: Publication Materials
**Duration**: 1-2 hours
**Priority**: MEDIUM

**Description**: Generate all figures, tables, and supplemental materials for publication.

**Tasks**:
1. Reproduce all 6 figures from paper
2. Generate Tables 1-3
3. Create supplemental materials
4. Export data for reproducibility

**Implementation Details**:
- File: `src/publication/figure_generator.py`
- DPI: 300+ for publication
- Formats: PDF, PNG, EPS
- Colorblind-friendly palettes

**Acceptance Criteria**:
- All figures match paper exactly
- Publication-ready quality
- Complete supplemental data package

---

## ğŸ“ Detailed File Structure

```
Euler-Product-Zero-Counting/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ s_t_functions.py          # âœ… Corrected S_euler
â”‚   â”‚   â”œâ”€â”€ s_t_functions_old.py      # Archive (to be deleted)
â”‚   â”‚   â””â”€â”€ prime_cache.py            # âœ… Prime utilities
â”‚   â”œâ”€â”€ experiments/
â”‚   â”‚   â”œâ”€â”€ dense_sampling.py         # Phase 2 (to create)
â”‚   â”‚   â”œâ”€â”€ phase_validation.py       # Phase 3
â”‚   â”‚   â”œâ”€â”€ comprehensive_diagnostics.py # Phase 4
â”‚   â”‚   â””â”€â”€ legacy_experiments.py     # Original tests
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ statistical_analysis.py   # Phase 5
â”‚   â”‚   â””â”€â”€ error_analysis.py         # Additional analysis
â”‚   â”œâ”€â”€ publication/
â”‚   â”‚   â”œâ”€â”€ figure_generator.py       # Phase 6
â”‚   â”‚   â”œâ”€â”€ table_generator.py        # Phase 6
â”‚   â”‚   â””â”€â”€ paper_templates/          # LaTeX templates
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ legacy_results_loader.py  # âœ… Data loader
â”‚   â”‚   â”œâ”€â”€ visualization.py          # Plot utilities
â”‚   â”‚   â””â”€â”€ statistics.py             # Statistical helpers
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_s_t_functions.py     # Unit tests
â”‚       â”œâ”€â”€ test_phase_validation.py  # Phase 3 tests
â”‚       â””â”€â”€ integration_tests.py      # End-to-end tests
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 10M_zeta_zeros.txt            # âœ… Input data
â”‚   â”œâ”€â”€ existing_results/             # âœ… Legacy data
â”‚   â”œâ”€â”€ processed/                    # Generated outputs
â”‚   â””â”€â”€ cache/                        # Computed caches
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ phase1/                       # S_euler verification
â”‚   â”œâ”€â”€ phase2/                       # Dense sampling âœ…
â”‚   â”œâ”€â”€ phase3/                       # Phase validation
â”‚   â”œâ”€â”€ phase4/                       # Diagnostics
â”‚   â”œâ”€â”€ phase5/                       # Statistical
â”‚   â””â”€â”€ publication/                  # Final figures
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API/                          # Code documentation
â”‚   â”œâ”€â”€ methodology/                  # Method details
â”‚   â””â”€â”€ tutorials/                    # Usage guides
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit_tests.py                 # Core functionality
â”‚   â”œâ”€â”€ integration_tests.py          # Full workflow
â”‚   â””â”€â”€ performance_tests.py          # Benchmarks
â”œâ”€â”€ phase2_dense_sampling_fast.py     # âœ… Phase 2 script
â”œâ”€â”€ test_phase1_complete.py           # âœ… Phase 1 script
â”œâ”€â”€ PROGRESS.md                       # âœ… Progress tracking
â”œâ”€â”€ PROJECT_PLAN.md                   # âœ… This file
â”œâ”€â”€ README.md                         # âœ… Updated
â”œâ”€â”€ requirements.txt                  # Dependencies
â”œâ”€â”€ setup.py                          # Package setup
â””â”€â”€ LICENSE                           # MIT License
```

---

## ğŸ”§ Technical Implementation Guidelines

### Code Standards
1. **Python 3.8+** compatibility
2. **Type hints** for all functions
3. **Docstrings** following NumPy style
4. **Black** formatting (line length 88)
5. **isort** for imports

### Performance Considerations
1. **Vectorized operations** with NumPy
2. **Chunked processing** for large datasets
3. **Memory mapping** for large files
4. **Parallel processing** where beneficial

### Verification Strategy
1. **Unit tests** for all core functions
2. **Integration tests** for workflows
3. **Legacy comparison** at each phase
4. **Numerical validation** with mpmath

### Documentation Requirements
1. **API docs** with Sphinx
2. **Method explanations** in docstrings
3. **Usage examples** in tutorials
4. **Citation information** for paper

---

## ğŸ“ˆ Resource Requirements

### Computational
- **CPU**: 8+ cores recommended
- **RAM**: 16GB for large datasets
- **Storage**: 5GB for all caches and outputs

### Timeline
- **Day 1 (Nov 17)**: âœ… Complete (Phases 1-2)
- **Day 2 (Nov 18)**: Phases 3-4 (5-6 hours)
- **Day 3 (Nov 19)**: Phases 5-6 + cleanup (3-4 hours)

### Dependencies
```python
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.5.0
seaborn>=0.11.0
scipy>=1.7.0
mpmath>=1.2.0
sympy>=1.9.0
pytest>=6.0.0
sphinx>=4.0.0
black>=21.0.0
isort>=5.9.0
```

---

## ğŸ¯ Success Criteria

1. **Functional Parity**: All original experiments reproducible
2. **Performance**: Faster than original notebook
3. **Maintainability**: Clean, documented, tested code
4. **Usability**: Easy to run and modify
5. **Completeness**: All figures and tables generated

---

## ğŸš¨ Risks and Mitigations

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Numerical precision issues | Medium | High | Use mpmath for verification |
| Performance bottleneck | Low | Medium | Profile and optimize hotspots |
| Missing legacy data | Low | High | Use provided existing results |
| Integration issues | Medium | Medium | Incremental testing |
| Deadline pressure | Medium | Medium | Focus on core functionality |

---

## ğŸ“ Post-Completion Tasks

1. **Code cleanup**: Remove old implementation
2. **Documentation**: Complete API docs
3. **Version tag**: v1.0.0 release
4. **Archive**: Original notebook to archive/
5. **README**: Final update with usage examples

---

*Last updated: November 17, 2024*
*Next review: November 18, 2024 (after Phase 3-4)*